{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "[flaml.automl: 11-04 14:16:13] {1488} INFO - Data split method: uniform\n",
      "[flaml.automl: 11-04 14:16:13] {1492} INFO - Evaluation method: cv\n",
      "[flaml.automl: 11-04 14:16:13] {1542} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 11-04 14:16:13] {1579} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree']\n",
      "[flaml.automl: 11-04 14:16:13] {1822} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:17] {1940} INFO - Estimated sufficient time budget=44869s. Estimated necessary time budget=45s.\n",
      "[flaml.automl: 11-04 14:16:17] {2025} INFO -  at 4.5s,\testimator lgbm's best error=0.6237,\tbest estimator lgbm's best error=0.6237\n",
      "[flaml.automl: 11-04 14:16:17] {1822} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:18] {2025} INFO -  at 4.8s,\testimator lgbm's best error=0.6237,\tbest estimator lgbm's best error=0.6237\n",
      "[flaml.automl: 11-04 14:16:18] {1822} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:18] {2025} INFO -  at 5.0s,\testimator lgbm's best error=0.3431,\tbest estimator lgbm's best error=0.3431\n",
      "[flaml.automl: 11-04 14:16:18] {1822} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:18] {2025} INFO -  at 5.4s,\testimator lgbm's best error=0.2475,\tbest estimator lgbm's best error=0.2475\n",
      "[flaml.automl: 11-04 14:16:18] {1822} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:18] {2025} INFO -  at 5.6s,\testimator lgbm's best error=0.2475,\tbest estimator lgbm's best error=0.2475\n",
      "[flaml.automl: 11-04 14:16:18] {1822} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:19] {2025} INFO -  at 5.9s,\testimator lgbm's best error=0.2048,\tbest estimator lgbm's best error=0.2048\n",
      "[flaml.automl: 11-04 14:16:19] {1822} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:19] {2025} INFO -  at 6.2s,\testimator lgbm's best error=0.2048,\tbest estimator lgbm's best error=0.2048\n",
      "[flaml.automl: 11-04 14:16:19] {1822} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:19] {2025} INFO -  at 6.4s,\testimator lgbm's best error=0.2048,\tbest estimator lgbm's best error=0.2048\n",
      "[flaml.automl: 11-04 14:16:19] {1822} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:20] {2025} INFO -  at 6.9s,\testimator lgbm's best error=0.1678,\tbest estimator lgbm's best error=0.1678\n",
      "[flaml.automl: 11-04 14:16:20] {1822} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:20] {2025} INFO -  at 7.2s,\testimator lgbm's best error=0.1678,\tbest estimator lgbm's best error=0.1678\n",
      "[flaml.automl: 11-04 14:16:20] {1822} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:21] {2025} INFO -  at 8.5s,\testimator lgbm's best error=0.1357,\tbest estimator lgbm's best error=0.1357\n",
      "[flaml.automl: 11-04 14:16:21] {1822} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 11-04 14:16:23] {2025} INFO -  at 9.9s,\testimator lgbm's best error=0.1357,\tbest estimator lgbm's best error=0.1357\n",
      "[flaml.automl: 11-04 14:16:23] {1822} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 11-04 14:16:24] {2025} INFO -  at 10.7s,\testimator xgboost's best error=5.5687,\tbest estimator lgbm's best error=0.1357\n",
      "[flaml.automl: 11-04 14:16:24] {2238} INFO - retrain lgbm for 0.4s\n",
      "[flaml.automl: 11-04 14:16:24] {2243} INFO - retrained model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
      "              learning_rate=0.17402065726724145, max_bin=255,\n",
      "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
      "              reg_alpha=0.0009765625, reg_lambda=0.006761362450996487,\n",
      "              verbose=-1)\n",
      "[flaml.automl: 11-04 14:16:24] {1604} INFO - fit succeeded\n",
      "[flaml.automl: 11-04 14:16:24] {1606} INFO - Time taken to find the best model: 8.507407426834106\n",
      "[flaml.automl: 11-04 14:16:24] {1620} WARNING - Time taken to find the best model is 85% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.78622115 22.051339   32.78755257 33.47652614 34.95828943 26.75332639\n",
      " 21.34396653 20.66357773 17.31616842 18.52194292 18.01053899 20.41336452\n",
      " 19.66394109 19.79133136 18.66216298 19.97408644 22.1095457  17.2957357\n",
      " 19.08514746 18.97639796 14.49844359 18.22090263 15.99802393 15.26399199\n",
      " 15.76911622 15.15722671 17.01770945 15.264859   18.58505666 20.67355352\n",
      " 14.41043377 18.06409463 14.34329903 15.17600192 14.49929086 21.16195835\n",
      " 21.31938078 22.16352523 22.66467468 30.40344579 34.04119479 29.06029195\n",
      " 24.47503988 24.2738795  22.03849929 20.77530844 21.4036324  17.71147016\n",
      " 16.41639882 18.6097649  20.88884116 21.57675915 25.07119115 21.61245173\n",
      " 17.58236844 34.28359116 23.41101983 30.69608477 23.07526194 20.71676839\n",
      " 19.51961319 17.94049499 22.96405927 24.07228768 32.26673362 25.85124221\n",
      " 19.70144544 20.65551648 19.45587573 20.74562648 24.11787779 20.56222379\n",
      " 23.0194683  23.45782543 24.47994748 23.10491545 20.94197526 22.19907492\n",
      " 21.78774017 21.43877668 26.93453719 24.8579991  24.45338144 22.88375808\n",
      " 22.97219054 26.43868366 21.5024433  22.64404035 27.30041961 29.06516527\n",
      " 23.65166955 23.37690188 23.68506109 25.97766885 21.20657056 26.83076187\n",
      " 21.99034484 39.97571935 43.19469935 33.12191932 24.17921098 24.86146833\n",
      " 18.01806868 20.48803729 20.60548796 18.17410971 18.07251658 20.48803729\n",
      " 20.60548796 18.29385185 21.06382752 23.18747227 18.72008865 19.1069423\n",
      " 21.09897541 18.38622539 21.08416577 20.73482139 18.31954533 20.72001174\n",
      " 22.26104964 21.95897322 19.55119493 17.07197308 19.55119493 20.7822871\n",
      " 16.4322712  15.83787012 16.15162273 15.54572528 19.67384472 19.38169988\n",
      " 20.3824107  16.63310748 16.43859722 17.1374118  16.18040938 18.19518385\n",
      " 13.64338661 15.87622612 13.73039535 13.45132835 14.54976899 14.54976899\n",
      " 13.74132288 14.65947372 17.49278686 13.74132288 14.54976899 14.75745268\n",
      " 20.5387173  18.74060765 18.20729254 17.33266574 17.7128667  16.09513647\n",
      " 15.63558649 39.79089704 24.68241835 24.25759899 24.89349392 48.36427281\n",
      " 48.75462974 49.45459682 21.78224124 22.95190481 49.55197963 21.27779161\n",
      " 22.28465292 22.04682546 20.35262467 21.27779161 21.37596992 24.24430162\n",
      " 22.49843597 27.68348708 22.20777307 24.26346919 29.20274349 36.79770089\n",
      " 42.47339808 30.19689982 37.34682082 31.61189145 24.65187954 27.16043876\n",
      " 48.96990201 28.23681851 29.99139984 34.77854769 33.34917062 30.35044477\n",
      " 34.82174311 28.73689603 28.69157412 48.13573163 34.35299513 30.39221382\n",
      " 33.18087033 32.32227815 33.45138941 23.82715125 44.42066223 48.13573163\n",
      " 48.13573163 23.24931355 23.14829459 21.28380061 22.24347355 19.13023461\n",
      " 20.2651681  19.06034241 21.28566599 26.05384406 20.85946824 24.23689021\n",
      " 21.84371822 25.15310382 20.45508822 22.43991128 28.34149112 20.27334921\n",
      " 27.07314206 26.0423654  45.74211388 46.26174944 42.96754681 31.36278928\n",
      " 46.20800847 31.0613375  22.4626915  31.13547806 44.0016304  45.69185058\n",
      " 27.1820404  22.81816414 25.76677824 33.07287723 23.9211382  25.06644201\n",
      " 25.08395673 20.29058733 21.25170296 24.47020491 18.74108948 17.95347583\n",
      " 21.74476786 20.45528054 22.39848502 25.52777264 23.83839212 26.77290971\n",
      " 32.44574856 41.16673516 22.05440569 20.62992843 43.68132975 50.53241893\n",
      " 35.47385231 32.26678852 35.5400416  44.25219497 46.78306202 32.10902159\n",
      " 35.42223005 22.86056296 30.2515088  47.38302583 45.15974253 21.95633697\n",
      " 21.70533374 24.81253613 24.21059678 36.27642088 31.25478606 32.3266354\n",
      " 33.76933643 30.80719529 26.17602821 34.11545817 45.83376295 35.02347171\n",
      " 46.40417786 48.33381452 30.2740428  22.15760041 21.58596779 23.37870635\n",
      " 22.45485931 24.27403248 32.16913203 33.7361614  28.64767271 23.21642\n",
      " 21.7624274  27.32485813 26.29825746 18.78648765 24.30564538 30.10167366\n",
      " 26.96139105 24.81220864 24.21438459 32.86071532 34.73858158 28.34555835\n",
      " 34.12777256 29.5479086  25.62652184 20.20255067 19.5577455  22.72768109\n",
      " 20.42003429 21.94744515 23.80863079 19.91915212 18.15105843 18.57753238\n",
      " 21.52715617 20.97856194 23.63753854 23.63753854 21.14378265 19.61053392\n",
      " 23.83869892 26.40515679 24.18161525 21.02659645 20.04006866 23.14870883\n",
      " 21.75333211 19.38601421 19.56035776 22.18693558 21.71965902 20.93665388\n",
      " 19.84119474 19.87654195 21.05852487 20.10731092 20.93071525 32.09862346\n",
      " 20.53711529 25.60925617 31.53655234 19.50874762 19.0879898  23.25667756\n",
      " 25.78408814 27.21328921 22.78800047 24.34439071 20.00180495 31.8126292\n",
      " 19.86716467 21.45546633 15.86719826 20.36840942 21.24569207 20.83415956\n",
      " 22.479684   19.51396853 20.58932591 17.90424196 28.98169086 25.37222589\n",
      " 19.15072501 21.12893141 47.15989754 50.70233641 48.72803488 48.7699185\n",
      " 45.06673338 13.90265042 15.56775944 17.8104956  12.69362861 12.26725049\n",
      " 10.35050028 10.81900247 12.36467763 10.2140777  11.42222113 11.18995599\n",
      "  8.70006146  8.47512484  9.63437161  7.94180972 10.03812611 11.42222113\n",
      " 16.13908178 17.52419177 10.24069089 14.19542516 12.93141772 14.48757\n",
      " 15.37729002 11.36538218  6.88474842  9.41803259  8.8919604  10.48124502\n",
      " 11.57843234 11.12963361  7.70108742  8.00546386 14.24078941 26.88455462\n",
      " 15.10978298 22.47329182 16.91452619 16.50459729 14.48100283 13.8925055\n",
      "  7.38063931  8.77739318  9.1496503   9.09609541  7.59790454  9.35809905\n",
      " 14.55991051 16.15282568 19.45414312 12.46041333 13.48916325  8.68853609\n",
      " 13.80031118 11.28916366 10.46768818 10.29133082 13.76215107 15.35001632\n",
      " 17.82351168 14.82239596 12.25586054 11.33379742 11.61686104  9.73689546\n",
      "  9.2717896  11.62066761 10.03591195 14.80489441 17.00179281 13.88244987\n",
      " 10.67459872  9.86491454 16.17164711 14.96574929 15.07691516 14.58219074\n",
      " 14.37893424 16.43232017 17.05844163 15.97818726 12.68955262 14.54699935\n",
      " 14.45814227 13.0724273  15.29178105 19.25885983 16.61102403 19.08525452\n",
      " 20.04387646 20.53996454 23.53523972 19.93101078 15.72513993 16.14926545\n",
      " 17.0461249  18.53357673 18.20378055 20.39552088 20.8075615  27.06962415\n",
      " 16.41025515 15.56971142 17.50943957 12.96572106 17.09869456 20.04645727\n",
      " 21.25838452 24.47175389 27.0440948  20.84154854 20.1567262  21.02179797\n",
      " 18.45008256 20.54104931 14.44793327 11.54982504 10.89761178 14.44793327\n",
      " 18.46165043 20.77238182 20.77238182 20.59386142 17.74025665 20.35858833\n",
      " 20.77238182 18.49881554 19.7667507  21.647574   18.90391845 25.10303289\n",
      " 23.09683415 16.70083954]\n",
      "<flaml.model.LGBMEstimator object at 0x7fee5285dfd0>\n"
     ]
    }
   ],
   "source": [
    "# AutoML\n",
    "# Regression Problem \n",
    "\n",
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "#Initialze an AutoML instance \n",
    "automl=AutoML()\n",
    "\n",
    "#Specify goal and  constraint\n",
    "automl_settings ={\n",
    "    \"time_budget\":10, # in seconds\n",
    "    \"metric\":'r2',\n",
    "    \"task\":'regression',\n",
    "    \"log_file_name\":\"boston.log\", \n",
    "}\n",
    "X_train, y_train= load_boston(return_X_y=True)\n",
    "# trained with labled input data\n",
    "automl.fit(X_train=X_train,y_train=y_train,**automl_settings)\n",
    "#predict\n",
    "print(automl.predict(X_train))\n",
    "#Export the best model\n",
    "print(automl.model)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec4f007d6c62ba27e72dc4eaede2153b380f92957ad692372108468a667c5304"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
